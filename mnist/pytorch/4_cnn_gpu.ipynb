{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Practice CNN with GPU support\r\n",
    "\r\n",
    "- switch model, loss function and variables to GPU with `cuda()` method\r\n",
    "- get data back from GPU with `cpu()` method, e.g. loss function\r\n",
    "\r\n",
    "**In this MINIST case, the default CNN calculated with cpu takes ~300s, while ~50s in GPU mode.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.autograd import Variable"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# 0 switch on/off gpu\r\n",
    "use_gpu = torch.cuda.is_available()\r\n",
    "device = torch.device(\"cuda\") if use_gpu else torch.device('cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 1 create model\r\n",
    "class CNN(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = nn.Sequential( # (1, 28, 28)\r\n",
    "            nn.Conv2d(\r\n",
    "                in_channels=1,\r\n",
    "                out_channels=16,\r\n",
    "                kernel_size=5,\r\n",
    "                stride=1,\r\n",
    "                padding=2 ),      # (16, 28, 28)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size=2),    # (16, 14, 14)\r\n",
    "        )\r\n",
    "        self.conv2 = nn.Sequential(  # (16, 14, 14)\r\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),  # (32, 14, 14)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2),  # (32, 7, 7)\r\n",
    "        )\r\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = self.conv2(x)\r\n",
    "        x = x.view(x.size(0), -1)   # (batch_size, 32 * 7 * 7)\r\n",
    "        output = self.out(x)\r\n",
    "        return output\r\n",
    "\r\n",
    "net = CNN()\r\n",
    "net.to(device)\r\n",
    "\r\n",
    "print(net)  # net architecture"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# 2 load data\r\n",
    "import torchvision\r\n",
    "import torch.utils.data as Data\r\n",
    "\r\n",
    "train_data = torchvision.datasets.MNIST(\r\n",
    "    root='./dataset/', \r\n",
    "    train=True,\r\n",
    "    transform=torchvision.transforms.ToTensor())\r\n",
    "\r\n",
    "test_data = torchvision.datasets.MNIST(\r\n",
    "    root='./dataset/', \r\n",
    "    train=False)\r\n",
    "\r\n",
    "train_data.data[0]\r\n",
    "\r\n",
    "# batch train data\r\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=32, shuffle=True)\r\n",
    "\r\n",
    "# preprocess test data\r\n",
    "# size: (n, 28, 28) -> (n, 1, 28, 28)\r\n",
    "# value [0, 255] -> [0, 1]\r\n",
    "with torch.no_grad():\r\n",
    "    test_x = Variable(torch.unsqueeze(test_data.data, dim=1)).type(torch.FloatTensor) / 255.0\r\n",
    "test_y = test_data.targets\r\n",
    "\r\n",
    "test_x = test_x.to(device)\r\n",
    "test_y = test_y.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# 3 train and evaluate model\r\n",
    "fun_loss = nn.CrossEntropyLoss().to(device) # cross entropy loss\r\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.02) # SGD Optimizer\r\n",
    "\r\n",
    "def evaluate(x, y):\r\n",
    "    '''\r\n",
    "    x: (n, 1, 28, 28)\r\n",
    "    y: (n, 10)\r\n",
    "    '''\r\n",
    "    out = net(x)\r\n",
    "    y_ = torch.max(out, 1)[1].detach() # max() return (value, index)\r\n",
    "    accuracy = sum(y_==y) / y.size(0)\r\n",
    "    return accuracy.item(), y_\r\n",
    "\r\n",
    "\r\n",
    "# training and testing\r\n",
    "for epoch in range(3):\r\n",
    "    for step, (x, y) in enumerate(train_loader): \r\n",
    "        # batch x, y variables\r\n",
    "        b_x = Variable(x).to(device)\r\n",
    "        b_y = Variable(y).to(device)\r\n",
    "\r\n",
    "        output = net(b_x)               # ann output\r\n",
    "        loss = fun_loss(output, b_y)    # cross entropy loss\r\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\r\n",
    "        loss.backward()                 # backpropagation, compute gradients\r\n",
    "        optimizer.step()                # apply gradients\r\n",
    "\r\n",
    "        if step%50 == 0:\r\n",
    "            accuracy, _ = evaluate(test_x, test_y)\r\n",
    "            if use_gpu: loss = loss.cpu()            \r\n",
    "            print(f'epoch: {epoch} | loss: {loss.detach().item()} | accuracy: {accuracy}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0 | loss: 2.306861639022827 | accuracy: 0.09699999541044235\n",
      "epoch: 0 | loss: 2.0436534881591797 | accuracy: 0.44429999589920044\n",
      "epoch: 0 | loss: 0.8002480268478394 | accuracy: 0.6563000082969666\n",
      "epoch: 0 | loss: 0.6530182361602783 | accuracy: 0.8509999513626099\n",
      "epoch: 0 | loss: 0.24696467816829681 | accuracy: 0.8830999732017517\n",
      "epoch: 0 | loss: 0.2814161777496338 | accuracy: 0.9017999768257141\n",
      "epoch: 0 | loss: 0.21604056656360626 | accuracy: 0.914900004863739\n",
      "epoch: 0 | loss: 0.29970452189445496 | accuracy: 0.9200999736785889\n",
      "epoch: 0 | loss: 0.2202242761850357 | accuracy: 0.9271000027656555\n",
      "epoch: 0 | loss: 0.32969406247138977 | accuracy: 0.9274999499320984\n",
      "epoch: 0 | loss: 0.1238674446940422 | accuracy: 0.9332000017166138\n",
      "epoch: 0 | loss: 0.16116076707839966 | accuracy: 0.9444999694824219\n",
      "epoch: 0 | loss: 0.18805715441703796 | accuracy: 0.9440000057220459\n",
      "epoch: 0 | loss: 0.19966737926006317 | accuracy: 0.9490999579429626\n",
      "epoch: 0 | loss: 0.5426671504974365 | accuracy: 0.9484999775886536\n",
      "epoch: 0 | loss: 0.2652387022972107 | accuracy: 0.9502999782562256\n",
      "epoch: 0 | loss: 0.08597703278064728 | accuracy: 0.9537999629974365\n",
      "epoch: 0 | loss: 0.13046962022781372 | accuracy: 0.9545999765396118\n",
      "epoch: 0 | loss: 0.17078015208244324 | accuracy: 0.9558999538421631\n",
      "epoch: 0 | loss: 0.0659649595618248 | accuracy: 0.9563999772071838\n",
      "epoch: 0 | loss: 0.3805773854255676 | accuracy: 0.9556999802589417\n",
      "epoch: 0 | loss: 0.024967003613710403 | accuracy: 0.9598999619483948\n",
      "epoch: 0 | loss: 0.1797943264245987 | accuracy: 0.9614999890327454\n",
      "epoch: 0 | loss: 0.08675029873847961 | accuracy: 0.9598000049591064\n",
      "epoch: 0 | loss: 0.10824300348758698 | accuracy: 0.957099974155426\n",
      "epoch: 0 | loss: 0.06783496588468552 | accuracy: 0.9648000001907349\n",
      "epoch: 0 | loss: 0.12829692661762238 | accuracy: 0.9638999700546265\n",
      "epoch: 0 | loss: 0.09441699832677841 | accuracy: 0.9648999571800232\n",
      "epoch: 0 | loss: 0.30135101079940796 | accuracy: 0.9648999571800232\n",
      "epoch: 0 | loss: 0.24137373268604279 | accuracy: 0.9598000049591064\n",
      "epoch: 0 | loss: 0.06752711534500122 | accuracy: 0.9696999788284302\n",
      "epoch: 0 | loss: 0.32907530665397644 | accuracy: 0.9612999558448792\n",
      "epoch: 0 | loss: 0.1716325283050537 | accuracy: 0.9715999960899353\n",
      "epoch: 0 | loss: 0.29211023449897766 | accuracy: 0.9747999906539917\n",
      "epoch: 0 | loss: 0.04666058346629143 | accuracy: 0.9698999524116516\n",
      "epoch: 0 | loss: 0.04039410129189491 | accuracy: 0.9698999524116516\n",
      "epoch: 0 | loss: 0.15578468143939972 | accuracy: 0.9705999493598938\n",
      "epoch: 0 | loss: 0.13709847629070282 | accuracy: 0.9690999984741211\n",
      "epoch: 1 | loss: 0.1728915423154831 | accuracy: 0.9726999998092651\n",
      "epoch: 1 | loss: 0.09338978677988052 | accuracy: 0.9679999947547913\n",
      "epoch: 1 | loss: 0.11554909497499466 | accuracy: 0.9741999506950378\n",
      "epoch: 1 | loss: 0.06979376077651978 | accuracy: 0.9751999974250793\n",
      "epoch: 1 | loss: 0.12642353773117065 | accuracy: 0.973099946975708\n",
      "epoch: 1 | loss: 0.19436192512512207 | accuracy: 0.9753999710083008\n",
      "epoch: 1 | loss: 0.04080874100327492 | accuracy: 0.9758999943733215\n",
      "epoch: 1 | loss: 0.016383327543735504 | accuracy: 0.9692999720573425\n",
      "epoch: 1 | loss: 0.01970089040696621 | accuracy: 0.9753999710083008\n",
      "epoch: 1 | loss: 0.0489388108253479 | accuracy: 0.974299967288971\n",
      "epoch: 1 | loss: 0.03630850464105606 | accuracy: 0.9723999500274658\n",
      "epoch: 1 | loss: 0.01912270300090313 | accuracy: 0.9749999642372131\n",
      "epoch: 1 | loss: 0.036480944603681564 | accuracy: 0.9749999642372131\n",
      "epoch: 1 | loss: 0.0157302375882864 | accuracy: 0.9776999950408936\n",
      "epoch: 1 | loss: 0.021878624334931374 | accuracy: 0.976099967956543\n",
      "epoch: 1 | loss: 0.11677566915750504 | accuracy: 0.9734999537467957\n",
      "epoch: 1 | loss: 0.018508559092879295 | accuracy: 0.9738999605178833\n",
      "epoch: 1 | loss: 0.0307270847260952 | accuracy: 0.976699948310852\n",
      "epoch: 1 | loss: 0.0761280432343483 | accuracy: 0.9785999655723572\n",
      "epoch: 1 | loss: 0.22152811288833618 | accuracy: 0.9724999666213989\n",
      "epoch: 1 | loss: 0.07427692413330078 | accuracy: 0.9772999882698059\n",
      "epoch: 1 | loss: 0.09311701357364655 | accuracy: 0.9751999974250793\n",
      "epoch: 1 | loss: 0.022296365350484848 | accuracy: 0.976099967956543\n",
      "epoch: 1 | loss: 0.18918295204639435 | accuracy: 0.9782999753952026\n",
      "epoch: 1 | loss: 0.18193373084068298 | accuracy: 0.9763000011444092\n",
      "epoch: 1 | loss: 0.029707588255405426 | accuracy: 0.9799999594688416\n",
      "epoch: 1 | loss: 0.09646075963973999 | accuracy: 0.9750999808311462\n",
      "epoch: 1 | loss: 0.04152768477797508 | accuracy: 0.9771999716758728\n",
      "epoch: 1 | loss: 0.0070112645626068115 | accuracy: 0.9793999791145325\n",
      "epoch: 1 | loss: 0.07560371607542038 | accuracy: 0.9787999987602234\n",
      "epoch: 1 | loss: 0.022626031190156937 | accuracy: 0.9802999496459961\n",
      "epoch: 1 | loss: 0.16532085835933685 | accuracy: 0.98089998960495\n",
      "epoch: 1 | loss: 0.2061152160167694 | accuracy: 0.9739999771118164\n",
      "epoch: 1 | loss: 0.03912525251507759 | accuracy: 0.9804999828338623\n",
      "epoch: 1 | loss: 0.047284021973609924 | accuracy: 0.9775999784469604\n",
      "epoch: 1 | loss: 0.0609954372048378 | accuracy: 0.9803999662399292\n",
      "epoch: 1 | loss: 0.030000129714608192 | accuracy: 0.9761999845504761\n",
      "epoch: 1 | loss: 0.03603542596101761 | accuracy: 0.979699969291687\n",
      "epoch: 2 | loss: 0.2608327567577362 | accuracy: 0.9768999814987183\n",
      "epoch: 2 | loss: 0.11239425837993622 | accuracy: 0.9807999730110168\n",
      "epoch: 2 | loss: 0.07092718034982681 | accuracy: 0.977400004863739\n",
      "epoch: 2 | loss: 0.03299903869628906 | accuracy: 0.976699948310852\n",
      "epoch: 2 | loss: 0.046456001698970795 | accuracy: 0.9820999503135681\n",
      "epoch: 2 | loss: 0.058905161917209625 | accuracy: 0.9802999496459961\n",
      "epoch: 2 | loss: 0.3132702112197876 | accuracy: 0.9803999662399292\n",
      "epoch: 2 | loss: 0.1753765046596527 | accuracy: 0.9806999564170837\n",
      "epoch: 2 | loss: 0.04858165606856346 | accuracy: 0.9818999767303467\n",
      "epoch: 2 | loss: 0.022995781153440475 | accuracy: 0.9792999625205994\n",
      "epoch: 2 | loss: 0.009422466158866882 | accuracy: 0.9818999767303467\n",
      "epoch: 2 | loss: 0.02206891030073166 | accuracy: 0.9803999662399292\n",
      "epoch: 2 | loss: 0.04780157655477524 | accuracy: 0.9801999926567078\n",
      "epoch: 2 | loss: 0.016805749386548996 | accuracy: 0.9806999564170837\n",
      "epoch: 2 | loss: 0.061332736164331436 | accuracy: 0.9811999797821045\n",
      "epoch: 2 | loss: 0.12641453742980957 | accuracy: 0.9837999939918518\n",
      "epoch: 2 | loss: 0.0029685816261917353 | accuracy: 0.9817000031471252\n",
      "epoch: 2 | loss: 0.21719041466712952 | accuracy: 0.9774999618530273\n",
      "epoch: 2 | loss: 0.01957625336945057 | accuracy: 0.979699969291687\n",
      "epoch: 2 | loss: 0.006168648134917021 | accuracy: 0.984499990940094\n",
      "epoch: 2 | loss: 0.07959473878145218 | accuracy: 0.9800999760627747\n",
      "epoch: 2 | loss: 0.03697142377495766 | accuracy: 0.982699990272522\n",
      "epoch: 2 | loss: 0.0654539167881012 | accuracy: 0.9838999509811401\n",
      "epoch: 2 | loss: 0.007445132359862328 | accuracy: 0.9827999472618103\n",
      "epoch: 2 | loss: 0.00803978368639946 | accuracy: 0.9799000024795532\n",
      "epoch: 2 | loss: 0.026331305503845215 | accuracy: 0.9835999608039856\n",
      "epoch: 2 | loss: 0.10716259479522705 | accuracy: 0.981499969959259\n",
      "epoch: 2 | loss: 0.1066538393497467 | accuracy: 0.9817000031471252\n",
      "epoch: 2 | loss: 0.011670304462313652 | accuracy: 0.9836999773979187\n",
      "epoch: 2 | loss: 0.11062774807214737 | accuracy: 0.981499969959259\n",
      "epoch: 2 | loss: 0.1501425802707672 | accuracy: 0.98089998960495\n",
      "epoch: 2 | loss: 0.04814973846077919 | accuracy: 0.9827999472618103\n",
      "epoch: 2 | loss: 0.05484190583229065 | accuracy: 0.9782999753952026\n",
      "epoch: 2 | loss: 0.037590038031339645 | accuracy: 0.9817999601364136\n",
      "epoch: 2 | loss: 0.020298460498452187 | accuracy: 0.9815999865531921\n",
      "epoch: 2 | loss: 0.11851814389228821 | accuracy: 0.9835999608039856\n",
      "epoch: 2 | loss: 0.013217200525105 | accuracy: 0.9846999645233154\n",
      "epoch: 2 | loss: 0.024631083011627197 | accuracy: 0.9846999645233154\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "0c9d8db05dfebc129cf9bbce5e1a2d1b6fc26aa76a4b80125bfb748781dcb1ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}