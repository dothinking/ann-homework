{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.autograd import Variable"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 1 create model\r\n",
    "class CNN(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = nn.Sequential( # (1, 28, 28)\r\n",
    "            nn.Conv2d(\r\n",
    "                in_channels=1,\r\n",
    "                out_channels=16,\r\n",
    "                kernel_size=5,\r\n",
    "                stride=1,\r\n",
    "                padding=2 ),      # (16, 28, 28)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size=2),    # (16, 14, 14)\r\n",
    "        )\r\n",
    "        self.conv2 = nn.Sequential(  # (16, 14, 14)\r\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),  # (32, 14, 14)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2),  # (32, 7, 7)\r\n",
    "        )\r\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = self.conv2(x)\r\n",
    "        x = x.view(x.size(0), -1)   # (batch_size, 32 * 7 * 7)\r\n",
    "        output = self.out(x)\r\n",
    "        return output\r\n",
    "\r\n",
    "net = CNN()\r\n",
    "print(net)  # net architecture"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 2 load data\r\n",
    "import torchvision\r\n",
    "import torch.utils.data as Data\r\n",
    "\r\n",
    "train_data = torchvision.datasets.MNIST(\r\n",
    "    root='./dataset/', \r\n",
    "    train=True,\r\n",
    "    transform=torchvision.transforms.ToTensor())\r\n",
    "\r\n",
    "test_data = torchvision.datasets.MNIST(\r\n",
    "    root='./dataset/', \r\n",
    "    train=False)\r\n",
    "\r\n",
    "train_data.data[0]\r\n",
    "\r\n",
    "# batch train data\r\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=32, shuffle=True)\r\n",
    "\r\n",
    "# preprocess test data\r\n",
    "# size: (n, 28, 28) -> (n, 1, 28, 28)\r\n",
    "# value [0, 255] -> [0, 1]\r\n",
    "with torch.no_grad():\r\n",
    "    test_x = Variable(torch.unsqueeze(test_data.data, dim=1)).type(torch.FloatTensor) / 255.0\r\n",
    "test_y = test_data.targets"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# 3 train and evaluate model\r\n",
    "fun_loss = nn.CrossEntropyLoss() # cross entropy loss\r\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.02) # SGD Optimizer\r\n",
    "\r\n",
    "def evaluate(x, y):\r\n",
    "    '''\r\n",
    "    x: (n, 1, 28, 28)\r\n",
    "    y: (n, 10)\r\n",
    "    '''\r\n",
    "    out = net(x)\r\n",
    "    y_ = torch.max(out, 1)[1].detach() # max() return (value, index)\r\n",
    "    accuracy = sum(y_==y) / y.size(0)\r\n",
    "    return accuracy.item(), y_\r\n",
    "\r\n",
    "\r\n",
    "# training and testing\r\n",
    "for epoch in range(3):\r\n",
    "    for step, (x, y) in enumerate(train_loader): \r\n",
    "        b_x = Variable(x)   # batch x\r\n",
    "        b_y = Variable(y)   # batch y\r\n",
    "\r\n",
    "        output = net(b_x)               # ann output\r\n",
    "        loss = fun_loss(output, b_y)    # cross entropy loss\r\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\r\n",
    "        loss.backward()                 # backpropagation, compute gradients\r\n",
    "        optimizer.step()                # apply gradients\r\n",
    "\r\n",
    "        if step%50 == 0:\r\n",
    "            accuracy, _ = evaluate(test_x, test_y)\r\n",
    "            print(f'epoch: {epoch} | loss: {loss.detach().item()} | accuracy: {accuracy}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0 | loss: 2.3022775650024414 | accuracy: 0.09589999914169312\n",
      "epoch: 0 | loss: 2.147660255432129 | accuracy: 0.4860000014305115\n",
      "epoch: 0 | loss: 0.9360531568527222 | accuracy: 0.6309000253677368\n",
      "epoch: 0 | loss: 0.8220655918121338 | accuracy: 0.8097000122070312\n",
      "epoch: 0 | loss: 0.20937883853912354 | accuracy: 0.8708999752998352\n",
      "epoch: 0 | loss: 0.7453866004943848 | accuracy: 0.890500009059906\n",
      "epoch: 0 | loss: 0.27988290786743164 | accuracy: 0.9071999788284302\n",
      "epoch: 0 | loss: 0.7935819625854492 | accuracy: 0.9049000144004822\n",
      "epoch: 0 | loss: 0.3070870339870453 | accuracy: 0.8985999822616577\n",
      "epoch: 0 | loss: 0.5050113797187805 | accuracy: 0.9289000034332275\n",
      "epoch: 0 | loss: 0.26430046558380127 | accuracy: 0.9395999908447266\n",
      "epoch: 0 | loss: 0.2305402159690857 | accuracy: 0.9229999780654907\n",
      "epoch: 0 | loss: 0.36997950077056885 | accuracy: 0.9391999840736389\n",
      "epoch: 0 | loss: 0.24583810567855835 | accuracy: 0.9394000172615051\n",
      "epoch: 0 | loss: 0.3160313069820404 | accuracy: 0.9473999738693237\n",
      "epoch: 0 | loss: 0.17636635899543762 | accuracy: 0.9283000230789185\n",
      "epoch: 0 | loss: 0.12094520032405853 | accuracy: 0.9485999941825867\n",
      "epoch: 0 | loss: 0.2598138749599457 | accuracy: 0.9397000074386597\n",
      "epoch: 0 | loss: 0.07973791658878326 | accuracy: 0.9528999924659729\n",
      "epoch: 0 | loss: 0.155683234333992 | accuracy: 0.9545999765396118\n",
      "epoch: 0 | loss: 0.17455698549747467 | accuracy: 0.9577000141143799\n",
      "epoch: 0 | loss: 0.06215588003396988 | accuracy: 0.9578999876976013\n",
      "epoch: 0 | loss: 0.1658627986907959 | accuracy: 0.9570000171661377\n",
      "epoch: 0 | loss: 0.11324907839298248 | accuracy: 0.9563000202178955\n",
      "epoch: 0 | loss: 0.14208926260471344 | accuracy: 0.9614999890327454\n",
      "epoch: 0 | loss: 0.2041761875152588 | accuracy: 0.9538999795913696\n",
      "epoch: 0 | loss: 0.30497702956199646 | accuracy: 0.9575999975204468\n",
      "epoch: 0 | loss: 0.06102119758725166 | accuracy: 0.9605000019073486\n",
      "epoch: 0 | loss: 0.35922104120254517 | accuracy: 0.9534000158309937\n",
      "epoch: 0 | loss: 0.11534141004085541 | accuracy: 0.9595999717712402\n",
      "epoch: 0 | loss: 0.08085344731807709 | accuracy: 0.9639999866485596\n",
      "epoch: 0 | loss: 0.07109960168600082 | accuracy: 0.9632999897003174\n",
      "epoch: 0 | loss: 0.10923893749713898 | accuracy: 0.9664999842643738\n",
      "epoch: 0 | loss: 0.3463573753833771 | accuracy: 0.9609000086784363\n",
      "epoch: 0 | loss: 0.09284903109073639 | accuracy: 0.9657999873161316\n",
      "epoch: 0 | loss: 0.1749458909034729 | accuracy: 0.9668999910354614\n",
      "epoch: 0 | loss: 0.12449796497821808 | accuracy: 0.9650999903678894\n",
      "epoch: 0 | loss: 0.036472924053668976 | accuracy: 0.9672999978065491\n",
      "epoch: 1 | loss: 0.13356678187847137 | accuracy: 0.9682000279426575\n",
      "epoch: 1 | loss: 0.07475728541612625 | accuracy: 0.9672999978065491\n",
      "epoch: 1 | loss: 0.12359581887722015 | accuracy: 0.968999981880188\n",
      "epoch: 1 | loss: 0.010300694964826107 | accuracy: 0.9695000052452087\n",
      "epoch: 1 | loss: 0.08725093305110931 | accuracy: 0.9649999737739563\n",
      "epoch: 1 | loss: 0.06725560873746872 | accuracy: 0.9717000126838684\n",
      "epoch: 1 | loss: 0.31949639320373535 | accuracy: 0.9715999960899353\n",
      "epoch: 1 | loss: 0.19273310899734497 | accuracy: 0.9733999967575073\n",
      "epoch: 1 | loss: 0.03613627701997757 | accuracy: 0.9713000059127808\n",
      "epoch: 1 | loss: 0.27356910705566406 | accuracy: 0.9707000255584717\n",
      "epoch: 1 | loss: 0.08516061305999756 | accuracy: 0.9736999869346619\n",
      "epoch: 1 | loss: 0.06871792674064636 | accuracy: 0.9732000231742859\n",
      "epoch: 1 | loss: 0.016553757712244987 | accuracy: 0.9700000286102295\n",
      "epoch: 1 | loss: 0.04948529601097107 | accuracy: 0.9753000140190125\n",
      "epoch: 1 | loss: 0.09185003489255905 | accuracy: 0.9735999703407288\n",
      "epoch: 1 | loss: 0.055433787405490875 | accuracy: 0.9745000004768372\n",
      "epoch: 1 | loss: 0.02232998237013817 | accuracy: 0.9735999703407288\n",
      "epoch: 1 | loss: 0.1770893782377243 | accuracy: 0.9761999845504761\n",
      "epoch: 1 | loss: 0.02460528165102005 | accuracy: 0.972000002861023\n",
      "epoch: 1 | loss: 0.13245660066604614 | accuracy: 0.9757999777793884\n",
      "epoch: 1 | loss: 0.042800236493349075 | accuracy: 0.9768000245094299\n",
      "epoch: 1 | loss: 0.08069033920764923 | accuracy: 0.97079998254776\n",
      "epoch: 1 | loss: 0.05325164645910263 | accuracy: 0.9764999747276306\n",
      "epoch: 1 | loss: 0.07086125016212463 | accuracy: 0.973800003528595\n",
      "epoch: 1 | loss: 0.045864738523960114 | accuracy: 0.9768000245094299\n",
      "epoch: 1 | loss: 0.022206410765647888 | accuracy: 0.9753000140190125\n",
      "epoch: 1 | loss: 0.0537855364382267 | accuracy: 0.9750000238418579\n",
      "epoch: 1 | loss: 0.041764892637729645 | accuracy: 0.9789999723434448\n",
      "epoch: 1 | loss: 0.023026298731565475 | accuracy: 0.9781000018119812\n",
      "epoch: 1 | loss: 0.39154723286628723 | accuracy: 0.9757000207901001\n",
      "epoch: 1 | loss: 0.3255576193332672 | accuracy: 0.977400004863739\n",
      "epoch: 1 | loss: 0.060910239815711975 | accuracy: 0.9779999852180481\n",
      "epoch: 1 | loss: 0.057257603853940964 | accuracy: 0.9778000116348267\n",
      "epoch: 1 | loss: 0.013881390914320946 | accuracy: 0.977400004863739\n",
      "epoch: 1 | loss: 0.06601490825414658 | accuracy: 0.9771999716758728\n",
      "epoch: 1 | loss: 0.04571231082081795 | accuracy: 0.9750000238418579\n",
      "epoch: 1 | loss: 0.020299995318055153 | accuracy: 0.9758999943733215\n",
      "epoch: 1 | loss: 0.08557754009962082 | accuracy: 0.9783999919891357\n",
      "epoch: 2 | loss: 0.20305633544921875 | accuracy: 0.979200005531311\n",
      "epoch: 2 | loss: 0.0068322233855724335 | accuracy: 0.9807000160217285\n",
      "epoch: 2 | loss: 0.03680617734789848 | accuracy: 0.9782000184059143\n",
      "epoch: 2 | loss: 0.010200303979218006 | accuracy: 0.9797999858856201\n",
      "epoch: 2 | loss: 0.036811571568250656 | accuracy: 0.9779000282287598\n",
      "epoch: 2 | loss: 0.03374229371547699 | accuracy: 0.98089998960495\n",
      "epoch: 2 | loss: 0.14373885095119476 | accuracy: 0.9804999828338623\n",
      "epoch: 2 | loss: 0.04414283484220505 | accuracy: 0.9790999889373779\n",
      "epoch: 2 | loss: 0.08734454214572906 | accuracy: 0.9775000214576721\n",
      "epoch: 2 | loss: 0.18339267373085022 | accuracy: 0.9805999994277954\n",
      "epoch: 2 | loss: 0.028005419299006462 | accuracy: 0.9807000160217285\n",
      "epoch: 2 | loss: 0.018698675557971 | accuracy: 0.9807000160217285\n",
      "epoch: 2 | loss: 0.025253821164369583 | accuracy: 0.9799000024795532\n",
      "epoch: 2 | loss: 0.16220006346702576 | accuracy: 0.9751999974250793\n",
      "epoch: 2 | loss: 0.04639451950788498 | accuracy: 0.9778000116348267\n",
      "epoch: 2 | loss: 0.01722889579832554 | accuracy: 0.9782000184059143\n",
      "epoch: 2 | loss: 0.16399356722831726 | accuracy: 0.9799000024795532\n",
      "epoch: 2 | loss: 0.012576533481478691 | accuracy: 0.9818999767303467\n",
      "epoch: 2 | loss: 0.023083152249455452 | accuracy: 0.9807999730110168\n",
      "epoch: 2 | loss: 0.07864836603403091 | accuracy: 0.9800999760627747\n",
      "epoch: 2 | loss: 0.04624637961387634 | accuracy: 0.9810000061988831\n",
      "epoch: 2 | loss: 0.07060924172401428 | accuracy: 0.9779000282287598\n",
      "epoch: 2 | loss: 0.10680752992630005 | accuracy: 0.9790999889373779\n",
      "epoch: 2 | loss: 0.048661600798368454 | accuracy: 0.9822999835014343\n",
      "epoch: 2 | loss: 0.009483982808887959 | accuracy: 0.9794999957084656\n",
      "epoch: 2 | loss: 0.05176033824682236 | accuracy: 0.9800000190734863\n",
      "epoch: 2 | loss: 0.009196184575557709 | accuracy: 0.9815999865531921\n",
      "epoch: 2 | loss: 0.029118090867996216 | accuracy: 0.9799000024795532\n",
      "epoch: 2 | loss: 0.01793796382844448 | accuracy: 0.980400025844574\n",
      "epoch: 2 | loss: 0.05767173320055008 | accuracy: 0.9819999933242798\n",
      "epoch: 2 | loss: 0.133711576461792 | accuracy: 0.9829999804496765\n",
      "epoch: 2 | loss: 0.04172857105731964 | accuracy: 0.9832000136375427\n",
      "epoch: 2 | loss: 0.045386869460344315 | accuracy: 0.9805999994277954\n",
      "epoch: 2 | loss: 0.01295840460807085 | accuracy: 0.9803000092506409\n",
      "epoch: 2 | loss: 0.051895029842853546 | accuracy: 0.9782999753952026\n",
      "epoch: 2 | loss: 0.004436769522726536 | accuracy: 0.9836000204086304\n",
      "epoch: 2 | loss: 0.23642326891422272 | accuracy: 0.9833999872207642\n",
      "epoch: 2 | loss: 0.050517454743385315 | accuracy: 0.9843999743461609\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "0c9d8db05dfebc129cf9bbce5e1a2d1b6fc26aa76a4b80125bfb748781dcb1ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}