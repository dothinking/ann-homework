{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch\r\n",
    "from captcha_dataset import CaptchaData\r\n",
    "from model import VGG"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load pytorch model: network + trained parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# 1.1 load vgg-like net\r\n",
    "image_size = (3, 60, 120)\r\n",
    "num_classes = 26*4\r\n",
    "conv_pattern = ((2, 64), (2, 128), (3, 256), (3, 512), (3, 512))\r\n",
    "hidden_pattern = (2, 512)\r\n",
    "    \r\n",
    "net = VGG(image_size, num_classes, conv_pattern, hidden_pattern, dropout=0.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "# 1.2 load trained parameters\r\n",
    "checkpoint = torch.load(\"./model.pt\")  \r\n",
    "net.load_state_dict(checkpoint)\r\n",
    "net.eval() # validation mode"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU(inplace=True)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=104, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Test pytorch model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "# 2.1 load test data\r\n",
    "test_dataset = CaptchaData('../samples/qq', train=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "# 2.2 test pytorch model\r\n",
    "image, label = test_dataset[0]\r\n",
    "y_torch = net(image.unsqueeze(0))\r\n",
    "\r\n",
    "print(y_torch)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-25.2161, -20.8584, -22.0234, -22.0476,  10.0669, -17.6713, -25.2594,\n",
      "         -27.7459, -30.1685, -28.7032, -28.6326, -21.3770, -29.2948, -26.2700,\n",
      "         -21.7358, -27.6670, -26.8095, -26.8388, -22.9397, -21.0337, -21.6800,\n",
      "         -22.3271, -29.8663, -24.5231, -19.7723, -28.7700, -23.4356, -30.3184,\n",
      "         -24.8494, -23.7260, -24.5259, -20.2181, -20.3613, -40.3949, -36.2767,\n",
      "         -27.1616, -26.2214, -31.5294, -27.9566, -30.6482, -26.4645,  10.0041,\n",
      "         -20.8672, -13.8068, -28.0826, -34.1110, -27.2392, -28.0956, -24.3233,\n",
      "         -32.1859, -34.9182, -28.9798, -14.9454, -23.2569, -22.4827, -15.6714,\n",
      "         -22.9747, -19.2316, -15.8154, -17.0972, -30.1884, -24.2281, -28.1569,\n",
      "         -17.8319, -22.0822, -23.5860, -14.1851, -20.5306,   6.1449, -15.5362,\n",
      "         -21.2989, -22.6076, -14.1713, -16.8409, -22.7419, -20.7258, -25.4364,\n",
      "         -23.2368, -27.5873, -27.5991, -23.6346, -26.3503, -28.6497, -25.5724,\n",
      "         -25.3335, -32.4916, -58.2927, -33.6981, -29.1249, -25.6687, -32.6754,\n",
      "         -27.2737, -20.9734, -24.8857, -34.3508, -27.2529,  11.8678, -28.5108,\n",
      "         -26.9947, -17.8237, -30.8209, -28.8260, -25.5897, -33.0224]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Convert pytorch model to onnx"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# 3.1 pytorch model to onnx model\r\n",
    "batch_size = 1\r\n",
    "x = torch.randn(batch_size, *image_size)\r\n",
    "export_onnx_file = \"model.onnx\"\r\n",
    "torch.onnx.export(net,\r\n",
    "        x,\r\n",
    "        export_onnx_file,\r\n",
    "        opset_version=9,\r\n",
    "        export_params=True,\r\n",
    "        verbose=False,\r\n",
    "        do_constant_folding=True,\r\n",
    "        input_names=[\"input\"],\r\n",
    "        output_names=[\"output0\"],\r\n",
    "        dynamic_axes={\"input\":{0:\"batch_size\"},\t\"output0\":{0:\"batch_size\"}})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "# 3.2 check onnx model\r\n",
    "import onnx\r\n",
    "\r\n",
    "# Load the ONNX model\r\n",
    "model = onnx.load(\"model.onnx\")\r\n",
    "\r\n",
    "# Check that the IR is well formed\r\n",
    "onnx.checker.check_model(model)\r\n",
    "\r\n",
    "# Print a human readable representation of the graph\r\n",
    "print(onnx.helper.printable_graph(model.graph))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "graph torch-jit-export (\n",
      "  %input[FLOAT, batch_sizex3x60x120]\n",
      ") initializers (\n",
      "  %145[FLOAT, 64x3x3x3]\n",
      "  %146[FLOAT, 64]\n",
      "  %148[FLOAT, 64x64x3x3]\n",
      "  %149[FLOAT, 64]\n",
      "  %151[FLOAT, 128x64x3x3]\n",
      "  %152[FLOAT, 128]\n",
      "  %154[FLOAT, 128x128x3x3]\n",
      "  %155[FLOAT, 128]\n",
      "  %157[FLOAT, 256x128x3x3]\n",
      "  %158[FLOAT, 256]\n",
      "  %160[FLOAT, 256x256x3x3]\n",
      "  %161[FLOAT, 256]\n",
      "  %163[FLOAT, 256x256x3x3]\n",
      "  %164[FLOAT, 256]\n",
      "  %166[FLOAT, 512x256x3x3]\n",
      "  %167[FLOAT, 512]\n",
      "  %169[FLOAT, 512x512x3x3]\n",
      "  %170[FLOAT, 512]\n",
      "  %172[FLOAT, 512x512x3x3]\n",
      "  %173[FLOAT, 512]\n",
      "  %175[FLOAT, 512x512x3x3]\n",
      "  %176[FLOAT, 512]\n",
      "  %178[FLOAT, 512x512x3x3]\n",
      "  %179[FLOAT, 512]\n",
      "  %181[FLOAT, 512x512x3x3]\n",
      "  %182[FLOAT, 512]\n",
      "  %classifier.0.bias[FLOAT, 512]\n",
      "  %classifier.0.weight[FLOAT, 512x1536]\n",
      "  %classifier.3.bias[FLOAT, 104]\n",
      "  %classifier.3.weight[FLOAT, 104x512]\n",
      ") {\n",
      "  %144 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input, %145, %146)\n",
      "  %98 = Relu(%144)\n",
      "  %147 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%98, %148, %149)\n",
      "  %101 = Relu(%147)\n",
      "  %102 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%101)\n",
      "  %150 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%102, %151, %152)\n",
      "  %105 = Relu(%150)\n",
      "  %153 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%105, %154, %155)\n",
      "  %108 = Relu(%153)\n",
      "  %109 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%108)\n",
      "  %156 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%109, %157, %158)\n",
      "  %112 = Relu(%156)\n",
      "  %159 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%112, %160, %161)\n",
      "  %115 = Relu(%159)\n",
      "  %162 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%115, %163, %164)\n",
      "  %118 = Relu(%162)\n",
      "  %119 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%118)\n",
      "  %165 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%119, %166, %167)\n",
      "  %122 = Relu(%165)\n",
      "  %168 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%122, %169, %170)\n",
      "  %125 = Relu(%168)\n",
      "  %171 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%125, %172, %173)\n",
      "  %128 = Relu(%171)\n",
      "  %129 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%128)\n",
      "  %174 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%129, %175, %176)\n",
      "  %132 = Relu(%174)\n",
      "  %177 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%132, %178, %179)\n",
      "  %135 = Relu(%177)\n",
      "  %180 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%135, %181, %182)\n",
      "  %138 = Relu(%180)\n",
      "  %139 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%138)\n",
      "  %140 = Flatten[axis = 1](%139)\n",
      "  %141 = Gemm[alpha = 1, beta = 1, transB = 1](%140, %classifier.0.weight, %classifier.0.bias)\n",
      "  %142 = Relu(%141)\n",
      "  %output0 = Gemm[alpha = 1, beta = 1, transB = 1](%142, %classifier.3.weight, %classifier.3.bias)\n",
      "  return %output0\n",
      "}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Deploy onnx model with opencv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "# 4.1 load onnx model \r\n",
    "import cv2\r\n",
    "onnx_net = cv2.dnn.readNet('model.onnx')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# 4.2 test loaded onnx model\r\n",
    "image, label = test_dataset[0]\r\n",
    "x = image.unsqueeze(0).numpy()\r\n",
    "onnx_net.setInput(x)\r\n",
    "y_onnx = onnx_net.forward()\r\n",
    "\r\n",
    "diff = (y_onnx-y_torch.detach().numpy())**2\r\n",
    "diff = diff.sum()**0.5\r\n",
    "\r\n",
    "print(diff)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6.522741919541013e-05\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "0c9d8db05dfebc129cf9bbce5e1a2d1b6fc26aa76a4b80125bfb748781dcb1ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}