{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Practice CNN with GPU support\r\n",
    "\r\n",
    "- switch model, loss function and variables to GPU with `cuda()` method\r\n",
    "- get data back from GPU with `cpu()` method, e.g. loss function\r\n",
    "\r\n",
    "**In this MINIST case, the default CNN calculated with cpu takes ~300s, while ~50s in GPU mode.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.autograd import Variable"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# 0 switch on/off gpu\r\n",
    "use_gpu = torch.cuda.is_available()\r\n",
    "device = torch.device(\"cuda\") if use_gpu else torch.device('cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 1 create model\r\n",
    "class CNN(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = nn.Sequential( # (1, 28, 28)\r\n",
    "            nn.Conv2d(\r\n",
    "                in_channels=1,\r\n",
    "                out_channels=16,\r\n",
    "                kernel_size=5,\r\n",
    "                stride=1,\r\n",
    "                padding=2 ),      # (16, 28, 28)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size=2),    # (16, 14, 14)\r\n",
    "        )\r\n",
    "        self.conv2 = nn.Sequential(  # (16, 14, 14)\r\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),  # (32, 14, 14)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2),  # (32, 7, 7)\r\n",
    "        )\r\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = self.conv2(x)\r\n",
    "        x = x.view(x.size(0), -1)   # (batch_size, 32 * 7 * 7)\r\n",
    "        output = self.out(x)\r\n",
    "        return output\r\n",
    "\r\n",
    "net = CNN()\r\n",
    "net.to(device)\r\n",
    "\r\n",
    "print(net)  # net architecture"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# 2 load data\r\n",
    "import torchvision\r\n",
    "import torch.utils.data as Data\r\n",
    "\r\n",
    "train_data = torchvision.datasets.MNIST(\r\n",
    "    root='./dataset/', \r\n",
    "    train=True,\r\n",
    "    transform=torchvision.transforms.ToTensor())\r\n",
    "\r\n",
    "test_data = torchvision.datasets.MNIST(\r\n",
    "    root='./dataset/', \r\n",
    "    train=False)\r\n",
    "\r\n",
    "train_data.data[0]\r\n",
    "\r\n",
    "# batch train data\r\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=32, shuffle=True)\r\n",
    "\r\n",
    "# preprocess test data\r\n",
    "# size: (n, 28, 28) -> (n, 1, 28, 28)\r\n",
    "# value [0, 255] -> [0, 1]\r\n",
    "with torch.no_grad():\r\n",
    "    test_x = Variable(torch.unsqueeze(test_data.data, dim=1)).type(torch.FloatTensor) / 255.0\r\n",
    "test_y = test_data.targets\r\n",
    "\r\n",
    "test_x = test_x.to(device)\r\n",
    "test_y = test_y.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 3 train and evaluate model\r\n",
    "fun_loss = nn.CrossEntropyLoss().to(device) # cross entropy loss\r\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.02) # SGD Optimizer\r\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.02)\r\n",
    "\r\n",
    "def evaluate(x, y):\r\n",
    "    '''\r\n",
    "    x: (n, 1, 28, 28)\r\n",
    "    y: (n, 10)\r\n",
    "    '''\r\n",
    "    out = net(x)\r\n",
    "    y_ = torch.max(out, 1)[1].detach() # max() return (value, index)\r\n",
    "    accuracy = sum(y_==y) / y.size(0)\r\n",
    "    return accuracy.item(), y_\r\n",
    "\r\n",
    "\r\n",
    "# training and testing\r\n",
    "for epoch in range(3):\r\n",
    "    for step, (x, y) in enumerate(train_loader): \r\n",
    "        # batch x, y variables\r\n",
    "        b_x = Variable(x).to(device)\r\n",
    "        b_y = Variable(y).to(device)\r\n",
    "\r\n",
    "        output = net(b_x)               # ann output\r\n",
    "        loss = fun_loss(output, b_y)    # cross entropy loss\r\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\r\n",
    "        loss.backward()                 # backpropagation, compute gradients\r\n",
    "        optimizer.step()                # apply gradients\r\n",
    "\r\n",
    "        if step%50 == 0:\r\n",
    "            accuracy, _ = evaluate(test_x, test_y)\r\n",
    "            if use_gpu: loss = loss.cpu()            \r\n",
    "            print(f'epoch: {epoch} | loss: {loss.detach().item()} | accuracy: {accuracy}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0 | loss: 0.009286634624004364 | accuracy: 0.1623999923467636\n",
      "epoch: 0 | loss: 0.06347671896219254 | accuracy: 0.9387999773025513\n",
      "epoch: 0 | loss: 0.39487653970718384 | accuracy: 0.9411999583244324\n",
      "epoch: 0 | loss: 0.1898575723171234 | accuracy: 0.9490999579429626\n",
      "epoch: 0 | loss: 0.14610183238983154 | accuracy: 0.9386999607086182\n",
      "epoch: 0 | loss: 0.10090676695108414 | accuracy: 0.9472999572753906\n",
      "epoch: 0 | loss: 0.3239684998989105 | accuracy: 0.9610999822616577\n",
      "epoch: 0 | loss: 0.3144674003124237 | accuracy: 0.9562999606132507\n",
      "epoch: 0 | loss: 0.027942165732383728 | accuracy: 0.9619999527931213\n",
      "epoch: 0 | loss: 0.09400998800992966 | accuracy: 0.9692999720573425\n",
      "epoch: 0 | loss: 0.00919688493013382 | accuracy: 0.9550999999046326\n",
      "epoch: 0 | loss: 0.11639679968357086 | accuracy: 0.9537999629974365\n",
      "epoch: 0 | loss: 0.051452457904815674 | accuracy: 0.957099974155426\n",
      "epoch: 0 | loss: 0.013265540823340416 | accuracy: 0.9651999473571777\n",
      "epoch: 0 | loss: 0.05242225155234337 | accuracy: 0.9620999693870544\n",
      "epoch: 0 | loss: 0.07079997658729553 | accuracy: 0.9616999626159668\n",
      "epoch: 0 | loss: 0.042524490505456924 | accuracy: 0.961899995803833\n",
      "epoch: 0 | loss: 0.1429143100976944 | accuracy: 0.9633999466896057\n",
      "epoch: 0 | loss: 0.2469572126865387 | accuracy: 0.9562000036239624\n",
      "epoch: 0 | loss: 0.07895942032337189 | accuracy: 0.9548999667167664\n",
      "epoch: 0 | loss: 0.07840381562709808 | accuracy: 0.9465999603271484\n",
      "epoch: 0 | loss: 0.016089368611574173 | accuracy: 0.9509999752044678\n",
      "epoch: 0 | loss: 0.1942821741104126 | accuracy: 0.943399965763092\n",
      "epoch: 0 | loss: 0.1012267917394638 | accuracy: 0.9399999976158142\n",
      "epoch: 0 | loss: 0.057902123779058456 | accuracy: 0.9569000005722046\n",
      "epoch: 0 | loss: 0.014245632104575634 | accuracy: 0.9530999660491943\n",
      "epoch: 0 | loss: 0.09585925936698914 | accuracy: 0.9666000008583069\n",
      "epoch: 0 | loss: 0.08661623299121857 | accuracy: 0.9508000016212463\n",
      "epoch: 0 | loss: 0.0617046132683754 | accuracy: 0.9702000021934509\n",
      "epoch: 0 | loss: 0.023566056042909622 | accuracy: 0.962399959564209\n",
      "epoch: 0 | loss: 0.0692240297794342 | accuracy: 0.955299973487854\n",
      "epoch: 0 | loss: 0.01598615199327469 | accuracy: 0.958299994468689\n",
      "epoch: 0 | loss: 0.055106021463871 | accuracy: 0.9609999656677246\n",
      "epoch: 0 | loss: 0.18811334669589996 | accuracy: 0.9602999687194824\n",
      "epoch: 0 | loss: 0.35592690110206604 | accuracy: 0.9615999460220337\n",
      "epoch: 0 | loss: 0.23397915065288544 | accuracy: 0.9635999798774719\n",
      "epoch: 0 | loss: 0.048116378486156464 | accuracy: 0.9635999798774719\n",
      "epoch: 0 | loss: 0.21977247297763824 | accuracy: 0.9506999850273132\n",
      "epoch: 1 | loss: 0.010592807084321976 | accuracy: 0.9594999551773071\n",
      "epoch: 1 | loss: 0.08177266269922256 | accuracy: 0.9682999849319458\n",
      "epoch: 1 | loss: 0.06225426122546196 | accuracy: 0.9598000049591064\n",
      "epoch: 1 | loss: 0.19938230514526367 | accuracy: 0.9608999490737915\n",
      "epoch: 1 | loss: 0.017103904858231544 | accuracy: 0.965399980545044\n",
      "epoch: 1 | loss: 0.2744281589984894 | accuracy: 0.9650999903678894\n",
      "epoch: 1 | loss: 0.02889637090265751 | accuracy: 0.9589999914169312\n",
      "epoch: 1 | loss: 0.07295724749565125 | accuracy: 0.9670999646186829\n",
      "epoch: 1 | loss: 0.13760225474834442 | accuracy: 0.9677000045776367\n",
      "epoch: 1 | loss: 0.4170723855495453 | accuracy: 0.9581999778747559\n",
      "epoch: 1 | loss: 0.000491210725158453 | accuracy: 0.9562999606132507\n",
      "epoch: 1 | loss: 0.11869524419307709 | accuracy: 0.9581999778747559\n",
      "epoch: 1 | loss: 0.30816206336021423 | accuracy: 0.9589999914169312\n",
      "epoch: 1 | loss: 0.49656644463539124 | accuracy: 0.9569999575614929\n",
      "epoch: 1 | loss: 0.233159601688385 | accuracy: 0.9573999643325806\n",
      "epoch: 1 | loss: 0.27495458722114563 | accuracy: 0.9591999650001526\n",
      "epoch: 1 | loss: 0.062348321080207825 | accuracy: 0.9563999772071838\n",
      "epoch: 1 | loss: 0.37579357624053955 | accuracy: 0.9559999704360962\n",
      "epoch: 1 | loss: 0.13075420260429382 | accuracy: 0.9487999677658081\n",
      "epoch: 1 | loss: 0.24526362121105194 | accuracy: 0.9675999879837036\n",
      "epoch: 1 | loss: 0.047060057520866394 | accuracy: 0.9655999541282654\n",
      "epoch: 1 | loss: 0.050252027809619904 | accuracy: 0.9601999521255493\n",
      "epoch: 1 | loss: 0.016253700479865074 | accuracy: 0.9596999883651733\n",
      "epoch: 1 | loss: 0.03729015588760376 | accuracy: 0.9603999853134155\n",
      "epoch: 1 | loss: 0.14854460954666138 | accuracy: 0.943399965763092\n",
      "epoch: 1 | loss: 0.017378948628902435 | accuracy: 0.9592999815940857\n",
      "epoch: 1 | loss: 0.08898811042308807 | accuracy: 0.9674999713897705\n",
      "epoch: 1 | loss: 0.1665305197238922 | accuracy: 0.9602999687194824\n",
      "epoch: 1 | loss: 0.024218549951910973 | accuracy: 0.9620999693870544\n",
      "epoch: 1 | loss: 0.2959187924861908 | accuracy: 0.9682999849319458\n",
      "epoch: 1 | loss: 0.2865010201931 | accuracy: 0.9650999903678894\n",
      "epoch: 1 | loss: 0.016468871384859085 | accuracy: 0.9648999571800232\n",
      "epoch: 1 | loss: 0.01709529012441635 | accuracy: 0.9681999683380127\n",
      "epoch: 1 | loss: 0.46058499813079834 | accuracy: 0.9587000012397766\n",
      "epoch: 1 | loss: 0.340936541557312 | accuracy: 0.9619999527931213\n",
      "epoch: 1 | loss: 0.22232358157634735 | accuracy: 0.9702999591827393\n",
      "epoch: 1 | loss: 0.07237063348293304 | accuracy: 0.9595999717712402\n",
      "epoch: 1 | loss: 0.08846311271190643 | accuracy: 0.9649999737739563\n",
      "epoch: 2 | loss: 0.08574561029672623 | accuracy: 0.9625999927520752\n",
      "epoch: 2 | loss: 0.026929602026939392 | accuracy: 0.9632999897003174\n",
      "epoch: 2 | loss: 0.16310279071331024 | accuracy: 0.9660999774932861\n",
      "epoch: 2 | loss: 0.0006647605332545936 | accuracy: 0.9602999687194824\n",
      "epoch: 2 | loss: 0.15856695175170898 | accuracy: 0.9607999920845032\n",
      "epoch: 2 | loss: 0.32414430379867554 | accuracy: 0.9422000050544739\n",
      "epoch: 2 | loss: 0.00150872056838125 | accuracy: 0.9609999656677246\n",
      "epoch: 2 | loss: 0.2401123344898224 | accuracy: 0.9401999711990356\n",
      "epoch: 2 | loss: 0.23696072399616241 | accuracy: 0.9511999487876892\n",
      "epoch: 2 | loss: 0.013693897984921932 | accuracy: 0.9627999663352966\n",
      "epoch: 2 | loss: 0.110147625207901 | accuracy: 0.9605000019073486\n",
      "epoch: 2 | loss: 0.23160186409950256 | accuracy: 0.9521999955177307\n",
      "epoch: 2 | loss: 0.14921286702156067 | accuracy: 0.9674999713897705\n",
      "epoch: 2 | loss: 0.3522540330886841 | accuracy: 0.9605000019073486\n",
      "epoch: 2 | loss: 0.003474478842690587 | accuracy: 0.9537999629974365\n",
      "epoch: 2 | loss: 0.35124748945236206 | accuracy: 0.967799961566925\n",
      "epoch: 2 | loss: 0.18077777326107025 | accuracy: 0.9575999975204468\n",
      "epoch: 2 | loss: 0.014873269945383072 | accuracy: 0.9605000019073486\n",
      "epoch: 2 | loss: 0.021792655810713768 | accuracy: 0.9711999893188477\n",
      "epoch: 2 | loss: 0.2841232419013977 | accuracy: 0.9531999826431274\n",
      "epoch: 2 | loss: 0.19677433371543884 | accuracy: 0.9483000040054321\n",
      "epoch: 2 | loss: 0.34909573197364807 | accuracy: 0.9590999484062195\n",
      "epoch: 2 | loss: 0.06692039966583252 | accuracy: 0.9638999700546265\n",
      "epoch: 2 | loss: 0.27507415413856506 | accuracy: 0.9650999903678894\n",
      "epoch: 2 | loss: 0.010785462334752083 | accuracy: 0.9661999940872192\n",
      "epoch: 2 | loss: 0.25407135486602783 | accuracy: 0.9657999873161316\n",
      "epoch: 2 | loss: 0.3909556567668915 | accuracy: 0.964199960231781\n",
      "epoch: 2 | loss: 0.03821253776550293 | accuracy: 0.9631999731063843\n",
      "epoch: 2 | loss: 0.16399729251861572 | accuracy: 0.9523999691009521\n",
      "epoch: 2 | loss: 0.0598662868142128 | accuracy: 0.955299973487854\n",
      "epoch: 2 | loss: 0.10239600390195847 | accuracy: 0.9528999924659729\n",
      "epoch: 2 | loss: 0.10510176420211792 | accuracy: 0.9607999920845032\n",
      "epoch: 2 | loss: 0.3400493264198303 | accuracy: 0.9685999751091003\n",
      "epoch: 2 | loss: 0.2278352826833725 | accuracy: 0.9555999636650085\n",
      "epoch: 2 | loss: 0.09250381588935852 | accuracy: 0.960099995136261\n",
      "epoch: 2 | loss: 0.25530868768692017 | accuracy: 0.9646999835968018\n",
      "epoch: 2 | loss: 0.12642285227775574 | accuracy: 0.9577999711036682\n",
      "epoch: 2 | loss: 0.15224836766719818 | accuracy: 0.9596999883651733\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "0c9d8db05dfebc129cf9bbce5e1a2d1b6fc26aa76a4b80125bfb748781dcb1ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}