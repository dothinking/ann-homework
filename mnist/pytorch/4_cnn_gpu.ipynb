{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Practice CNN with GPU support\r\n",
    "\r\n",
    "- switch model, loss function and variables to GPU with `cuda()` method\r\n",
    "- get data back from GPU with `cpu()` method, e.g. loss function\r\n",
    "\r\n",
    "**In this MINIST case, the default CNN calculated with cpu takes ~300s, while ~50s in GPU mode.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.autograd import Variable"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 0 switch on/off gpu\r\n",
    "use_gpu = torch.cuda.is_available()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 1 create model\r\n",
    "class CNN(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = nn.Sequential( # (1, 28, 28)\r\n",
    "            nn.Conv2d(\r\n",
    "                in_channels=1,\r\n",
    "                out_channels=16,\r\n",
    "                kernel_size=5,\r\n",
    "                stride=1,\r\n",
    "                padding=2 ),      # (16, 28, 28)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size=2),    # (16, 14, 14)\r\n",
    "        )\r\n",
    "        self.conv2 = nn.Sequential(  # (16, 14, 14)\r\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),  # (32, 14, 14)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2),  # (32, 7, 7)\r\n",
    "        )\r\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = self.conv2(x)\r\n",
    "        x = x.view(x.size(0), -1)   # (batch_size, 32 * 7 * 7)\r\n",
    "        output = self.out(x)\r\n",
    "        return output\r\n",
    "\r\n",
    "net = CNN()\r\n",
    "if use_gpu: net = net.cuda()\r\n",
    "\r\n",
    "print(net)  # net architecture"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# 2 load data\r\n",
    "import torchvision\r\n",
    "import torch.utils.data as Data\r\n",
    "\r\n",
    "train_data = torchvision.datasets.MNIST(\r\n",
    "    root='./dataset/', \r\n",
    "    train=True,\r\n",
    "    transform=torchvision.transforms.ToTensor())\r\n",
    "\r\n",
    "test_data = torchvision.datasets.MNIST(\r\n",
    "    root='./dataset/', \r\n",
    "    train=False)\r\n",
    "\r\n",
    "train_data.data[0]\r\n",
    "\r\n",
    "# batch train data\r\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=32, shuffle=True)\r\n",
    "\r\n",
    "# preprocess test data\r\n",
    "# size: (n, 28, 28) -> (n, 1, 28, 28)\r\n",
    "# value [0, 255] -> [0, 1]\r\n",
    "with torch.no_grad():\r\n",
    "    test_x = Variable(torch.unsqueeze(test_data.data, dim=1)).type(torch.FloatTensor) / 255.0\r\n",
    "test_y = test_data.targets\r\n",
    "\r\n",
    "if use_gpu:\r\n",
    "    test_x = test_x.cuda()\r\n",
    "    test_y = test_y.cuda()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 3 train and evaluate model\r\n",
    "fun_loss = nn.CrossEntropyLoss() # cross entropy loss\r\n",
    "if use_gpu: \r\n",
    "    fun_loss = fun_loss.cuda()\r\n",
    "\r\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.02) # SGD Optimizer\r\n",
    "\r\n",
    "\r\n",
    "def evaluate(x, y):\r\n",
    "    '''\r\n",
    "    x: (n, 1, 28, 28)\r\n",
    "    y: (n, 10)\r\n",
    "    '''\r\n",
    "    out = net(x)\r\n",
    "    y_ = torch.max(out, 1)[1].detach() # max() return (value, index)\r\n",
    "    accuracy = sum(y_==y) / y.size(0)\r\n",
    "    return accuracy.item(), y_\r\n",
    "\r\n",
    "\r\n",
    "# training and testing\r\n",
    "for epoch in range(3):\r\n",
    "    for step, (x, y) in enumerate(train_loader): \r\n",
    "        # batch x, y variables\r\n",
    "        if use_gpu: \r\n",
    "            b_x = Variable(x.cuda())\r\n",
    "            b_y = Variable(y.cuda())\r\n",
    "        else:\r\n",
    "            b_x = Variable(x)\r\n",
    "            b_y = Variable(y)   \r\n",
    "\r\n",
    "        output = net(b_x)               # ann output\r\n",
    "        loss = fun_loss(output, b_y)    # cross entropy loss\r\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\r\n",
    "        loss.backward()                 # backpropagation, compute gradients\r\n",
    "        optimizer.step()                # apply gradients\r\n",
    "\r\n",
    "        if step%50 == 0:\r\n",
    "            accuracy, _ = evaluate(test_x, test_y)\r\n",
    "            if use_gpu: loss = loss.cpu()            \r\n",
    "            print(f'epoch: {epoch} | loss: {loss.detach().item()} | accuracy: {accuracy}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0 | loss: 0.0757799744606018 | accuracy: 0.9825999736785889\n",
      "epoch: 0 | loss: 0.04405032843351364 | accuracy: 0.9820999503135681\n",
      "epoch: 0 | loss: 0.0028308623004704714 | accuracy: 0.9835999608039856\n",
      "epoch: 0 | loss: 0.0035960767418146133 | accuracy: 0.9819999933242798\n",
      "epoch: 0 | loss: 0.00780661404132843 | accuracy: 0.9829999804496765\n",
      "epoch: 0 | loss: 0.022393101826310158 | accuracy: 0.9842000007629395\n",
      "epoch: 0 | loss: 0.0037588062696158886 | accuracy: 0.982699990272522\n",
      "epoch: 0 | loss: 0.041846923530101776 | accuracy: 0.98499995470047\n",
      "epoch: 0 | loss: 0.1274210810661316 | accuracy: 0.9830999970436096\n",
      "epoch: 0 | loss: 0.016850095242261887 | accuracy: 0.9819999933242798\n",
      "epoch: 0 | loss: 0.08465032279491425 | accuracy: 0.9787999987602234\n",
      "epoch: 0 | loss: 0.014006481505930424 | accuracy: 0.983199954032898\n",
      "epoch: 0 | loss: 0.07772214710712433 | accuracy: 0.983199954032898\n",
      "epoch: 0 | loss: 0.06476686149835587 | accuracy: 0.9797999858856201\n",
      "epoch: 0 | loss: 0.004607530776411295 | accuracy: 0.9817000031471252\n",
      "epoch: 0 | loss: 0.07764469087123871 | accuracy: 0.9835999608039856\n",
      "epoch: 0 | loss: 0.08127211779356003 | accuracy: 0.9843999743461609\n",
      "epoch: 0 | loss: 0.048974309116601944 | accuracy: 0.9830999970436096\n",
      "epoch: 0 | loss: 0.11991710960865021 | accuracy: 0.9813999533653259\n",
      "epoch: 0 | loss: 0.19684240221977234 | accuracy: 0.9822999835014343\n",
      "epoch: 0 | loss: 0.01878056488931179 | accuracy: 0.9829999804496765\n",
      "epoch: 0 | loss: 0.02123260125517845 | accuracy: 0.9820999503135681\n",
      "epoch: 0 | loss: 0.07463251799345016 | accuracy: 0.983199954032898\n",
      "epoch: 0 | loss: 0.037480149418115616 | accuracy: 0.983299970626831\n",
      "epoch: 0 | loss: 0.05780259892344475 | accuracy: 0.9842999577522278\n",
      "epoch: 0 | loss: 0.011835504323244095 | accuracy: 0.9830999970436096\n",
      "epoch: 0 | loss: 0.006324583198875189 | accuracy: 0.9843999743461609\n",
      "epoch: 0 | loss: 0.009751208126544952 | accuracy: 0.983199954032898\n",
      "epoch: 0 | loss: 0.02858971804380417 | accuracy: 0.9822999835014343\n",
      "epoch: 0 | loss: 0.09018494933843613 | accuracy: 0.9810999631881714\n",
      "epoch: 0 | loss: 0.1611991673707962 | accuracy: 0.9827999472618103\n",
      "epoch: 0 | loss: 0.2919931709766388 | accuracy: 0.9804999828338623\n",
      "epoch: 0 | loss: 0.004519104957580566 | accuracy: 0.9786999821662903\n",
      "epoch: 0 | loss: 0.028600625693798065 | accuracy: 0.9809999465942383\n",
      "epoch: 0 | loss: 0.015944581478834152 | accuracy: 0.9838999509811401\n",
      "epoch: 0 | loss: 0.019571712240576744 | accuracy: 0.9840999841690063\n",
      "epoch: 0 | loss: 0.11582975089550018 | accuracy: 0.9806999564170837\n",
      "epoch: 0 | loss: 0.08819852024316788 | accuracy: 0.9813999533653259\n",
      "epoch: 1 | loss: 0.0068584829568862915 | accuracy: 0.9838999509811401\n",
      "epoch: 1 | loss: 0.0878034308552742 | accuracy: 0.982699990272522\n",
      "epoch: 1 | loss: 0.0391579307615757 | accuracy: 0.9817000031471252\n",
      "epoch: 1 | loss: 0.18527650833129883 | accuracy: 0.9828999638557434\n",
      "epoch: 1 | loss: 0.012981765903532505 | accuracy: 0.9846999645233154\n",
      "epoch: 1 | loss: 0.011988618411123753 | accuracy: 0.9846999645233154\n",
      "epoch: 1 | loss: 0.04176105931401253 | accuracy: 0.9861999750137329\n",
      "epoch: 1 | loss: 0.009043357335031033 | accuracy: 0.9840999841690063\n",
      "epoch: 1 | loss: 0.07549877464771271 | accuracy: 0.98499995470047\n",
      "epoch: 1 | loss: 0.011046160012483597 | accuracy: 0.9836999773979187\n",
      "epoch: 1 | loss: 0.06392227113246918 | accuracy: 0.9858999848365784\n",
      "epoch: 1 | loss: 0.03780383616685867 | accuracy: 0.9821999669075012\n",
      "epoch: 1 | loss: 0.009808014146983624 | accuracy: 0.9789999723434448\n",
      "epoch: 1 | loss: 0.014819031581282616 | accuracy: 0.9843999743461609\n",
      "epoch: 1 | loss: 0.05528973788022995 | accuracy: 0.9861999750137329\n",
      "epoch: 1 | loss: 0.07273469120264053 | accuracy: 0.984499990940094\n",
      "epoch: 1 | loss: 0.04696023091673851 | accuracy: 0.9842999577522278\n",
      "epoch: 1 | loss: 0.045933231711387634 | accuracy: 0.982699990272522\n",
      "epoch: 1 | loss: 0.11160756647586823 | accuracy: 0.9842999577522278\n",
      "epoch: 1 | loss: 0.002131546614691615 | accuracy: 0.9838999509811401\n",
      "epoch: 1 | loss: 0.16867317259311676 | accuracy: 0.9835000038146973\n",
      "epoch: 1 | loss: 0.011967740952968597 | accuracy: 0.984499990940094\n",
      "epoch: 1 | loss: 0.13322904706001282 | accuracy: 0.9833999872207642\n",
      "epoch: 1 | loss: 0.029088646173477173 | accuracy: 0.9864999651908875\n",
      "epoch: 1 | loss: 0.02520989067852497 | accuracy: 0.984499990940094\n",
      "epoch: 1 | loss: 0.003687244141474366 | accuracy: 0.9855999946594238\n",
      "epoch: 1 | loss: 0.04488440603017807 | accuracy: 0.98499995470047\n",
      "epoch: 1 | loss: 0.08338449150323868 | accuracy: 0.9789999723434448\n",
      "epoch: 1 | loss: 0.06244385987520218 | accuracy: 0.9853000044822693\n",
      "epoch: 1 | loss: 0.01753455027937889 | accuracy: 0.9839999675750732\n",
      "epoch: 1 | loss: 0.025458121672272682 | accuracy: 0.9840999841690063\n",
      "epoch: 1 | loss: 0.13658949732780457 | accuracy: 0.9856999516487122\n",
      "epoch: 1 | loss: 0.002121701603755355 | accuracy: 0.9860000014305115\n",
      "epoch: 1 | loss: 0.009642116725444794 | accuracy: 0.9850999712944031\n",
      "epoch: 1 | loss: 0.0039977882988750935 | accuracy: 0.9824000000953674\n",
      "epoch: 1 | loss: 0.002999821212142706 | accuracy: 0.9866999983787537\n",
      "epoch: 1 | loss: 0.06518127024173737 | accuracy: 0.9843999743461609\n",
      "epoch: 1 | loss: 0.02969016507267952 | accuracy: 0.9857999682426453\n",
      "epoch: 2 | loss: 0.3493999242782593 | accuracy: 0.98499995470047\n",
      "epoch: 2 | loss: 0.03646622970700264 | accuracy: 0.9858999848365784\n",
      "epoch: 2 | loss: 0.022365272045135498 | accuracy: 0.9853999614715576\n",
      "epoch: 2 | loss: 0.02217905782163143 | accuracy: 0.98499995470047\n",
      "epoch: 2 | loss: 0.0080876424908638 | accuracy: 0.9863999485969543\n",
      "epoch: 2 | loss: 0.00324625289067626 | accuracy: 0.986299991607666\n",
      "epoch: 2 | loss: 0.012149874120950699 | accuracy: 0.9865999817848206\n",
      "epoch: 2 | loss: 0.02792617678642273 | accuracy: 0.9856999516487122\n",
      "epoch: 2 | loss: 0.02165595255792141 | accuracy: 0.9857999682426453\n",
      "epoch: 2 | loss: 0.013578338548541069 | accuracy: 0.9835999608039856\n",
      "epoch: 2 | loss: 0.24643607437610626 | accuracy: 0.9858999848365784\n",
      "epoch: 2 | loss: 0.1700534075498581 | accuracy: 0.9836999773979187\n",
      "epoch: 2 | loss: 0.13154342770576477 | accuracy: 0.9847999811172485\n",
      "epoch: 2 | loss: 0.005155283957719803 | accuracy: 0.9842000007629395\n",
      "epoch: 2 | loss: 0.025115948170423508 | accuracy: 0.9865999817848206\n",
      "epoch: 2 | loss: 0.01383949350565672 | accuracy: 0.9833999872207642\n",
      "epoch: 2 | loss: 0.04617670923471451 | accuracy: 0.9853999614715576\n",
      "epoch: 2 | loss: 0.07694265991449356 | accuracy: 0.9851999878883362\n",
      "epoch: 2 | loss: 0.17820069193840027 | accuracy: 0.9866999983787537\n",
      "epoch: 2 | loss: 0.007468509022146463 | accuracy: 0.984499990940094\n",
      "epoch: 2 | loss: 0.023861881345510483 | accuracy: 0.9858999848365784\n",
      "epoch: 2 | loss: 0.015091149136424065 | accuracy: 0.9864999651908875\n",
      "epoch: 2 | loss: 0.04764235392212868 | accuracy: 0.9846999645233154\n",
      "epoch: 2 | loss: 0.07720215618610382 | accuracy: 0.984499990940094\n",
      "epoch: 2 | loss: 0.002762921154499054 | accuracy: 0.9863999485969543\n",
      "epoch: 2 | loss: 0.22132690250873566 | accuracy: 0.9860000014305115\n",
      "epoch: 2 | loss: 0.14005640149116516 | accuracy: 0.9848999977111816\n",
      "epoch: 2 | loss: 0.017478328198194504 | accuracy: 0.9858999848365784\n",
      "epoch: 2 | loss: 0.04031187295913696 | accuracy: 0.9850999712944031\n",
      "epoch: 2 | loss: 0.028385140001773834 | accuracy: 0.9882999658584595\n",
      "epoch: 2 | loss: 0.00553741492331028 | accuracy: 0.9865999817848206\n",
      "epoch: 2 | loss: 0.14697781205177307 | accuracy: 0.9875999689102173\n",
      "epoch: 2 | loss: 0.010808136314153671 | accuracy: 0.986299991607666\n",
      "epoch: 2 | loss: 0.021394124254584312 | accuracy: 0.984499990940094\n",
      "epoch: 2 | loss: 0.10794314742088318 | accuracy: 0.9856999516487122\n",
      "epoch: 2 | loss: 0.01919524557888508 | accuracy: 0.9875999689102173\n",
      "epoch: 2 | loss: 0.010971566662192345 | accuracy: 0.9865999817848206\n",
      "epoch: 2 | loss: 0.002589323790743947 | accuracy: 0.986799955368042\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "0c9d8db05dfebc129cf9bbce5e1a2d1b6fc26aa76a4b80125bfb748781dcb1ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}