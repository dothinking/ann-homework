{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Simplify model definition with Sequential Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.autograd import Variable"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 1 create model\r\n",
    "net = nn.Sequential(\r\n",
    "    nn.Linear(28*28, 256),\r\n",
    "    nn.ReLU(),\r\n",
    "    nn.Linear(256, 128),\r\n",
    "    nn.ReLU(),\r\n",
    "    nn.Linear(128, 10) \r\n",
    ")\r\n",
    "print(net)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# 2 load data\r\n",
    "import torchvision\r\n",
    "import torch.utils.data as Data\r\n",
    "\r\n",
    "train_data = torchvision.datasets.MNIST(\r\n",
    "    root='./dataset/', \r\n",
    "    train=True,\r\n",
    "    transform=torchvision.transforms.ToTensor())\r\n",
    "\r\n",
    "test_data = torchvision.datasets.MNIST(\r\n",
    "    root='./dataset/', \r\n",
    "    train=False)\r\n",
    "\r\n",
    "train_data.data[0]\r\n",
    "\r\n",
    "# batch train data\r\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=32, shuffle=True)\r\n",
    "\r\n",
    "# preprocess test data\r\n",
    "# size: (n, 28, 28) -> (n, 28*28)\r\n",
    "# value [0, 255] -> [0, 1]\r\n",
    "with torch.no_grad():\r\n",
    "    test_x = Variable(test_data.data.view(-1, 28*28)).type(torch.FloatTensor) / 255.0\r\n",
    "test_y = test_data.targets"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# 3 train and evaluate model\r\n",
    "fun_loss = nn.CrossEntropyLoss() # cross entropy loss\r\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.02) # SGD Optimizer\r\n",
    "\r\n",
    "def evaluate(x, y):\r\n",
    "    '''\r\n",
    "    x: (n, 1, 28, 28)\r\n",
    "    y: (n, 10)\r\n",
    "    '''\r\n",
    "    out = net(x)\r\n",
    "    y_ = torch.max(out, 1)[1].detach() # max() return (value, index)\r\n",
    "    accuracy = sum(y_==y) / y.size(0)\r\n",
    "    return accuracy.item(), y_\r\n",
    "\r\n",
    "\r\n",
    "# training and testing\r\n",
    "for epoch in range(3):\r\n",
    "    for step, (x, y) in enumerate(train_loader): \r\n",
    "        b_x = Variable(x.view(x.size(0), -1))   # batch x\r\n",
    "        b_y = Variable(y)   # batch y\r\n",
    "\r\n",
    "        output = net(b_x)               # ann output\r\n",
    "        loss = fun_loss(output, b_y)    # cross entropy loss\r\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\r\n",
    "        loss.backward()                 # backpropagation, compute gradients\r\n",
    "        optimizer.step()                # apply gradients\r\n",
    "\r\n",
    "        if step%50 == 0:\r\n",
    "            accuracy, _ = evaluate(test_x, test_y)\r\n",
    "            print(f'epoch: {epoch} | loss: {loss.detach().item()} | accuracy: {accuracy}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0 | loss: 0.41487565636634827 | accuracy: 0.9399999976158142\n",
      "epoch: 0 | loss: 0.1505737155675888 | accuracy: 0.9434000253677368\n",
      "epoch: 0 | loss: 0.2794940769672394 | accuracy: 0.9419000148773193\n",
      "epoch: 0 | loss: 0.06305766850709915 | accuracy: 0.9380000233650208\n",
      "epoch: 0 | loss: 0.09588237851858139 | accuracy: 0.9398999810218811\n",
      "epoch: 0 | loss: 0.09343711286783218 | accuracy: 0.9444000124931335\n",
      "epoch: 0 | loss: 0.18010397255420685 | accuracy: 0.9422000050544739\n",
      "epoch: 0 | loss: 0.1423468291759491 | accuracy: 0.9447000026702881\n",
      "epoch: 0 | loss: 0.03807302191853523 | accuracy: 0.9437999725341797\n",
      "epoch: 0 | loss: 0.09074410796165466 | accuracy: 0.9462000131607056\n",
      "epoch: 0 | loss: 0.39455974102020264 | accuracy: 0.9476000070571899\n",
      "epoch: 0 | loss: 0.07555022835731506 | accuracy: 0.9470999836921692\n",
      "epoch: 0 | loss: 0.14707492291927338 | accuracy: 0.9462000131607056\n",
      "epoch: 0 | loss: 0.19503110647201538 | accuracy: 0.9463000297546387\n",
      "epoch: 0 | loss: 0.09398728609085083 | accuracy: 0.9458000063896179\n",
      "epoch: 0 | loss: 0.19748620688915253 | accuracy: 0.9462000131607056\n",
      "epoch: 0 | loss: 0.07821347564458847 | accuracy: 0.9465000033378601\n",
      "epoch: 0 | loss: 0.08005911856889725 | accuracy: 0.948199987411499\n",
      "epoch: 0 | loss: 0.28883203864097595 | accuracy: 0.9485999941825867\n",
      "epoch: 0 | loss: 0.13917993009090424 | accuracy: 0.9484000205993652\n",
      "epoch: 0 | loss: 0.2649889886379242 | accuracy: 0.9498000144958496\n",
      "epoch: 0 | loss: 0.03927310183644295 | accuracy: 0.9480999708175659\n",
      "epoch: 0 | loss: 0.08253789693117142 | accuracy: 0.948199987411499\n",
      "epoch: 0 | loss: 0.3981577754020691 | accuracy: 0.949400007724762\n",
      "epoch: 0 | loss: 0.3467238247394562 | accuracy: 0.9485999941825867\n",
      "epoch: 0 | loss: 0.12631085515022278 | accuracy: 0.9496999979019165\n",
      "epoch: 0 | loss: 0.2597084045410156 | accuracy: 0.9510999917984009\n",
      "epoch: 0 | loss: 0.2026296705007553 | accuracy: 0.9508000016212463\n",
      "epoch: 0 | loss: 0.6542354226112366 | accuracy: 0.9485999941825867\n",
      "epoch: 0 | loss: 0.3747439682483673 | accuracy: 0.9491999745368958\n",
      "epoch: 0 | loss: 0.18032002449035645 | accuracy: 0.9506999850273132\n",
      "epoch: 0 | loss: 0.0984686091542244 | accuracy: 0.9503999948501587\n",
      "epoch: 0 | loss: 0.14817631244659424 | accuracy: 0.9505000114440918\n",
      "epoch: 0 | loss: 0.03745553642511368 | accuracy: 0.9501000046730042\n",
      "epoch: 0 | loss: 0.35750046372413635 | accuracy: 0.9488999843597412\n",
      "epoch: 0 | loss: 0.04518550634384155 | accuracy: 0.9517999887466431\n",
      "epoch: 0 | loss: 0.0884140282869339 | accuracy: 0.95169997215271\n",
      "epoch: 0 | loss: 0.2200455665588379 | accuracy: 0.9509999752044678\n",
      "epoch: 1 | loss: 0.3518689274787903 | accuracy: 0.949999988079071\n",
      "epoch: 1 | loss: 0.11577108502388 | accuracy: 0.95169997215271\n",
      "epoch: 1 | loss: 0.21205827593803406 | accuracy: 0.9506999850273132\n",
      "epoch: 1 | loss: 0.26926732063293457 | accuracy: 0.9523000121116638\n",
      "epoch: 1 | loss: 0.13665367662906647 | accuracy: 0.9532999992370605\n",
      "epoch: 1 | loss: 0.2342604696750641 | accuracy: 0.9519000053405762\n",
      "epoch: 1 | loss: 0.0700935423374176 | accuracy: 0.9537000060081482\n",
      "epoch: 1 | loss: 0.08805825561285019 | accuracy: 0.9531999826431274\n",
      "epoch: 1 | loss: 0.48353052139282227 | accuracy: 0.9537000060081482\n",
      "epoch: 1 | loss: 0.14863505959510803 | accuracy: 0.9520000219345093\n",
      "epoch: 1 | loss: 0.2054733783006668 | accuracy: 0.9537000060081482\n",
      "epoch: 1 | loss: 0.06158323585987091 | accuracy: 0.954200029373169\n",
      "epoch: 1 | loss: 0.04427788406610489 | accuracy: 0.9531999826431274\n",
      "epoch: 1 | loss: 0.18235912919044495 | accuracy: 0.9542999863624573\n",
      "epoch: 1 | loss: 0.2235553115606308 | accuracy: 0.9538999795913696\n",
      "epoch: 1 | loss: 0.1677265465259552 | accuracy: 0.9534000158309937\n",
      "epoch: 1 | loss: 0.18167932331562042 | accuracy: 0.9556000232696533\n",
      "epoch: 1 | loss: 0.17805616557598114 | accuracy: 0.9537000060081482\n",
      "epoch: 1 | loss: 0.07776689529418945 | accuracy: 0.9544000029563904\n",
      "epoch: 1 | loss: 0.1392178237438202 | accuracy: 0.9555000066757202\n",
      "epoch: 1 | loss: 0.05975761264562607 | accuracy: 0.9553999900817871\n",
      "epoch: 1 | loss: 0.1556023806333542 | accuracy: 0.9569000005722046\n",
      "epoch: 1 | loss: 0.2938172519207001 | accuracy: 0.9557999968528748\n",
      "epoch: 1 | loss: 0.0237942673265934 | accuracy: 0.9544000029563904\n",
      "epoch: 1 | loss: 0.2763669192790985 | accuracy: 0.9553999900817871\n",
      "epoch: 1 | loss: 0.03216267749667168 | accuracy: 0.9559999704360962\n",
      "epoch: 1 | loss: 0.16166163980960846 | accuracy: 0.954800009727478\n",
      "epoch: 1 | loss: 0.2914423942565918 | accuracy: 0.9559000134468079\n",
      "epoch: 1 | loss: 0.1788831204175949 | accuracy: 0.957099974155426\n",
      "epoch: 1 | loss: 0.2163659781217575 | accuracy: 0.9564999938011169\n",
      "epoch: 1 | loss: 0.13673223555088043 | accuracy: 0.9552000164985657\n",
      "epoch: 1 | loss: 0.06009943410754204 | accuracy: 0.9578999876976013\n",
      "epoch: 1 | loss: 0.09147443622350693 | accuracy: 0.9567999839782715\n",
      "epoch: 1 | loss: 0.35617581009864807 | accuracy: 0.9574999809265137\n",
      "epoch: 1 | loss: 0.05539539083838463 | accuracy: 0.9563999772071838\n",
      "epoch: 1 | loss: 0.13384923338890076 | accuracy: 0.9569000005722046\n",
      "epoch: 1 | loss: 0.17128898203372955 | accuracy: 0.9545999765396118\n",
      "epoch: 1 | loss: 0.14332154393196106 | accuracy: 0.9571999907493591\n",
      "epoch: 2 | loss: 0.037705130875110626 | accuracy: 0.9592999815940857\n",
      "epoch: 2 | loss: 0.10955801606178284 | accuracy: 0.9592000246047974\n",
      "epoch: 2 | loss: 0.06299415975809097 | accuracy: 0.9580000042915344\n",
      "epoch: 2 | loss: 0.2043638527393341 | accuracy: 0.9585000276565552\n",
      "epoch: 2 | loss: 0.04342668503522873 | accuracy: 0.9575999975204468\n",
      "epoch: 2 | loss: 0.07666360586881638 | accuracy: 0.9581999778747559\n",
      "epoch: 2 | loss: 0.16743232309818268 | accuracy: 0.9596999883651733\n",
      "epoch: 2 | loss: 0.07144609093666077 | accuracy: 0.9606999754905701\n",
      "epoch: 2 | loss: 0.059256915003061295 | accuracy: 0.9581000208854675\n",
      "epoch: 2 | loss: 0.015646569430828094 | accuracy: 0.9598000049591064\n",
      "epoch: 2 | loss: 0.128139927983284 | accuracy: 0.9592000246047974\n",
      "epoch: 2 | loss: 0.04274920001626015 | accuracy: 0.9575999975204468\n",
      "epoch: 2 | loss: 0.0827646479010582 | accuracy: 0.9592000246047974\n",
      "epoch: 2 | loss: 0.05401783809065819 | accuracy: 0.958899974822998\n",
      "epoch: 2 | loss: 0.03614122048020363 | accuracy: 0.9591000080108643\n",
      "epoch: 2 | loss: 0.08547142893075943 | accuracy: 0.9605000019073486\n",
      "epoch: 2 | loss: 0.12253899872303009 | accuracy: 0.9602000117301941\n",
      "epoch: 2 | loss: 0.14042715728282928 | accuracy: 0.9599000215530396\n",
      "epoch: 2 | loss: 0.16094888746738434 | accuracy: 0.9613000154495239\n",
      "epoch: 2 | loss: 0.144746333360672 | accuracy: 0.9595999717712402\n",
      "epoch: 2 | loss: 0.10966498404741287 | accuracy: 0.9605000019073486\n",
      "epoch: 2 | loss: 0.20532378554344177 | accuracy: 0.9610999822616577\n",
      "epoch: 2 | loss: 0.20070290565490723 | accuracy: 0.9616000056266785\n",
      "epoch: 2 | loss: 0.0454736053943634 | accuracy: 0.9581000208854675\n",
      "epoch: 2 | loss: 0.23010459542274475 | accuracy: 0.9613000154495239\n",
      "epoch: 2 | loss: 0.12155679613351822 | accuracy: 0.9602000117301941\n",
      "epoch: 2 | loss: 0.05620748549699783 | accuracy: 0.9595000147819519\n",
      "epoch: 2 | loss: 0.10714590549468994 | accuracy: 0.9606999754905701\n",
      "epoch: 2 | loss: 0.11786361038684845 | accuracy: 0.9621000289916992\n",
      "epoch: 2 | loss: 0.025159981101751328 | accuracy: 0.9606999754905701\n",
      "epoch: 2 | loss: 0.05250667408108711 | accuracy: 0.9621999859809875\n",
      "epoch: 2 | loss: 0.2812516987323761 | accuracy: 0.9621999859809875\n",
      "epoch: 2 | loss: 0.07048144191503525 | accuracy: 0.9617999792098999\n",
      "epoch: 2 | loss: 0.11663907021284103 | accuracy: 0.9613000154495239\n",
      "epoch: 2 | loss: 0.09306859970092773 | accuracy: 0.9627000093460083\n",
      "epoch: 2 | loss: 0.1752081960439682 | accuracy: 0.9614999890327454\n",
      "epoch: 2 | loss: 0.0470770001411438 | accuracy: 0.9634000062942505\n",
      "epoch: 2 | loss: 0.4809434115886688 | accuracy: 0.9614999890327454\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "0c9d8db05dfebc129cf9bbce5e1a2d1b6fc26aa76a4b80125bfb748781dcb1ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}